% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/class_recall.R
\name{recall}
\alias{recall}
\alias{TPR}
<<<<<<< HEAD
\alias{sensitivity}
\alias{hitrate}
\alias{FNR}
\title{Recall | Sensitivity | True Positive Rate | Hit rate}
=======
\alias{FNR}
\title{Recall | Sensitivity | True Positive Rate}
>>>>>>> master
\usage{
recall(
  data = NULL,
  obs,
  pred,
  atom = FALSE,
  pos_level = 2,
  tidy = FALSE,
  na.rm = TRUE
)

TPR(
  data = NULL,
  obs,
  pred,
  atom = FALSE,
  pos_level = 2,
  tidy = FALSE,
  na.rm = TRUE
)

<<<<<<< HEAD
sensitivity(
  data = NULL,
  obs,
  pred,
  atom = FALSE,
  pos_level = 2,
  tidy = FALSE,
  na.rm = TRUE
)

hitrate(
  data = NULL,
  obs,
  pred,
  atom = FALSE,
  pos_level = 2,
  tidy = FALSE,
  na.rm = TRUE
)

=======
>>>>>>> master
FNR(
  data = NULL,
  obs,
  pred,
  atom = FALSE,
  pos_level = 2,
  tidy = FALSE,
  na.rm = TRUE
)
}
\arguments{
\item{data}{(Optional) argument to call an existing data frame containing the data.}

\item{obs}{Vector with observed values (character | factor).}

\item{pred}{Vector with predicted values (character | factor).}

\item{atom}{Logical operator (TRUE/FALSE) to decide if the estimate is made for
each class (atom = TRUE) or at a global level (atom = FALSE); Default : FALSE.
When dataset is "binomial" atom does not apply.}

\item{pos_level}{Integer, for binary cases, indicating the order (1|2) of the level
corresponding to the positive. Generally, the positive level is the second (2)
since following an alpha-numeric order, the most common pairs are
\code{(Negative | Positive)}, \code{(0 | 1)}, \code{(FALSE | TRUE)}. Default : 2.}

\item{tidy}{Logical operator (TRUE/FALSE) to decide the type of return. TRUE
returns a data.frame, FALSE returns a list; Default : FALSE.}

\item{na.rm}{Logic argument to remove rows with missing values
(NA). Default is na.rm = TRUE.}
}
\value{
an object of class \code{numeric} within a \code{list} (if tidy = FALSE) or within a
\verb{data frame} (if tidy = TRUE).
}
\description{
\code{recall} estimates the recall (a.k.a. sensitivity, true
positive rate -TPR-, or hit rate) for a nominal/categorical predicted-observed dataset.

\code{TPR} alternative to \code{recall()}.

\code{sensitivity} alternative to \code{recall()}.

\code{hitrate} alternative to \code{recall()}.

\code{TNR} alternative renamed version of \code{recall()}.

\code{FNR} estimates false negative rate (or false alarm, or fall-out)
for a nominal/categorical predicted-observed dataset.
}
\details{
The \code{recall} (a.k.a. sensitivity or true positive rate -TPR-) is a
non-normalized coefficient that represents the ratio between the correctly
predicted cases (true positives -TP-) to the total number of actual observations
that belong to a given class (actual positives -P-).

For binomial cases, \eqn{recall  =  \frac{TP}{P} = \frac{TP}{TP + FN} }

The \code{recall} metric is bounded between 0 and 1. The closer to 1 the better.
Values towards zero indicate low performance. It can be either estimated for
each particular class or at a global level.

Metrica offers 4 identical alternative functions that do the same job: i) \code{recall},
ii) \code{sensitivity}, iii) \code{TPR}, and iv) \code{hitrate}. However, consider
when using \code{metrics_summary}, only the \code{recall} alternative is used.

The false negative rate (or false alarm, or fall-out) is the complement of the
recall, representing the ratio between the number of false negatives (FN)
to the actual number of positives (P). The \code{FNR} formula is:

\eqn{FNR = 1 - recall = 1 - TPR = \frac{FN}{P}}

The \code{fpr} is bounded between 0 and 1. The closer to 0 the better. Low performance
is indicated with fpr > 0.5.

For the formula and more details, see
\href{https://adriancorrendo.github.io/metrica/articles/available_metrics_classification.html}{online-documentation}
}
\examples{
\donttest{
set.seed(123)
# Two-class
binomial_case <- data.frame(labels = sample(c("True","False"), 100, 
replace = TRUE), predictions = sample(c("True","False"), 100, replace = TRUE))

# Multi-class
multinomial_case <- data.frame(labels = sample(c("Red","Blue", "Green"), 100, 
replace = TRUE), predictions = sample(c("Red","Blue", "Green"), 100, replace = TRUE))

# Get recall estimate for two-class case at global level
recall(data = binomial_case, obs = labels, pred = predictions, tidy = TRUE)

# Get FNR estimate for two-class case at global level
FNR(data = binomial_case, obs = labels, pred = predictions, tidy = TRUE)

# Get recall estimate for each class for the multi-class case at global level
recall(data = multinomial_case, obs = labels, pred = predictions, tidy = TRUE, 
atom = FALSE)

# Get recall estimate for the multi-class case at a class-level
recall(data = multinomial_case, obs = labels, pred = predictions, tidy = TRUE,
atom = TRUE)
}
}
\references{
Ting K.M. (2017)
Precision and Recall.
\emph{In: Sammut C., Webb G.I. (eds) Encyclopedia of Machine Learning and Data Mining.}
\emph{Springer, Boston, MA.} \doi{10.1007/978-1-4899-7687-1_659}

Ting K.M. (2017).
Sensitivity.
\emph{In: Sammut C., Webb G.I. (eds) Encyclopedia of Machine Learning and Data Mining.}
\emph{Springer, Boston, MA.} \doi{10.1007/978-1-4899-7687-1_751}

Trevethan, R. (2017).
\emph{Sensitivity, Specificity, and Predictive Values: Foundations, Pliabilities, and Pitfalls}
_ in Research and Practice. Front. Public Health 5:307_ \doi{10.3389/fpubh.2017.00307}
}
