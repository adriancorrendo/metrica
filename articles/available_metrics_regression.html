<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="metrica">
<title>Regression performance metrics and indices • metrica</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.2.2/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.2.2/bootstrap.bundle.min.js"></script><link href="../deps/Barlow_Condensed-0.4.5/font.css" rel="stylesheet">
<link href="../deps/Ubuntu_Mono-0.4.5/font.css" rel="stylesheet">
<link href="../deps/Barlow_Semi_Condensed-0.4.5/font.css" rel="stylesheet">
<!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- bootstrap-toc --><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@v1.0.1/dist/bootstrap-toc.min.js" integrity="sha256-4veVQbu7//Lk5TSmc7YV48MxtMy98e26cf5MrgZYnwo=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Regression performance metrics and indices">
<meta property="og:description" content="metrica">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-dark navbar-expand-lg bg-primary"><div class="container">
    
    <a class="navbar-brand me-2" href="../index.html">metrica</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">2.0.3</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item">
  <a class="nav-link" href="../reference/index.html">
    <span class="fa fa-gears"></span>
     
    Functions
  </a>
</li>
<li class="nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown--metrics">
    <span class="fa fa-ruler"></span>
     
    Metrics
  </a>
  <div class="dropdown-menu" aria-labelledby="dropdown--metrics">
    <a class="dropdown-item" href="../articles/regression_case.html">Regression performance</a>
    <a class="dropdown-item" href="../articles/regression_case.html">Classification performance</a>
  </div>
</li>
<li class="nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown--tutorials">
    <span class="fa fa-paperclip"></span>
     
    Tutorials
  </a>
  <div class="dropdown-menu" aria-labelledby="dropdown--tutorials">
    <a class="dropdown-item" href="../articles/regression_case.html">Regression</a>
    <a class="dropdown-item" href="../articles/regression_case.html">Classification</a>
    <a class="dropdown-item" href="../articles/apsim_open.html">Import APSIM files</a>
  </div>
</li>
<li class="nav-item">
  <a class="nav-link" href="../articles/Cheatsheet.html">
    <span class="fa fa-note-sticky"></span>
     
    Cheatsheet
  </a>
</li>
<li class="nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown--more">
    <span class="fa fa-plus"></span>
     
    More
  </a>
  <div class="dropdown-menu" aria-labelledby="dropdown--more">
    <a class="dropdown-item" href="../articles/JOSS_publication.html">JOSS publication</a>
    <a class="dropdown-item" href="../articles/Shinyapp.html">Shinyapp</a>
  </div>
</li>
<li class="nav-item">
  <a class="nav-link" href="../news/index.html">
    <span class="fa fa-newspaper"></span>
     
    News
  </a>
</li>
      </ul>
<form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../search.json" id="search-input" placeholder="Search for" autocomplete="off">
</form>

      <ul class="navbar-nav">
<li class="nav-item">
  <a class="external-link nav-link" href="https://github.com/adriancorrendo/metrica/">
    <span class="fa fa-github"></span>
     
  </a>
</li>
<li class="nav-item">
  <a class="external-link nav-link" href="https://adriancorrendo.github.io/">
    <span class="fa fa-user"></span>
     
  </a>
</li>
      </ul>
</div>

    
  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="" class="logo" alt=""><h1>Regression performance metrics and indices</h1>
                        <h4 data-toc-skip class="author">Adrian
Correndo</h4>
            
            <h4 data-toc-skip class="date">2023-04-12</h4>
      
      <small class="dont-index">Source: <a href="https://github.com/adriancorrendo/metrica/blob/HEAD/vignettes/available_metrics_regression.Rmd" class="external-link"><code>vignettes/available_metrics_regression.Rmd</code></a></small>
      <div class="d-none name"><code>available_metrics_regression.Rmd</code></div>
    </div>

    
    
<div class="section level2">
<h2 id="description">Description <br><a class="anchor" aria-label="anchor" href="#description"></a>
</h2>
<p>The <strong>metrica</strong> package compiles +80 functions to assess
regression (continuous) and classification (categorical) prediction
performance from multiple perspectives. <br></p>
<p>For regression models, it includes 4 plotting functions (scatter,
tiles, density, &amp; Bland-Altman plots), and 48 prediction performance
scores including error metrics (MBE, MAE, RAE, RMAE, MAPE, SMAPE, MSE,
RMSE, RRMSE, RSR, PBE, iqRMSE), error decomposition (MLA, MLP, PLA, PLP,
PAB, PPB, SB, SDSD, LCS, Ub, Uc, Ue), model efficiency (NSE, E1, Erel,
KGE), indices of agreement (d, d1, d1r, RAC, AC, lambda), goodness of
fit (r, R2, RSS, TSS, RSE), adjusted correlation coefficients (CCC, Xa,
distance correlation-dcorr-, maximal information coefficient -MIC-),
variability (uSD, var_u), and symmetric regression coefficients (B0_sma,
B1_sma). Specifically for time-series predictions, <code>metrica</code>
also includes the Mean Absolute Scaled Error (MASE). <br></p>
<p>For supervised models, always keep in mind the concept of
“cross-validation” since predicted values should ideally come from
out-of-bag samples (unseen by training sets) to avoid overestimation of
the prediction performance. <br></p>
</div>
<div class="section level2">
<h2 id="using-the-functions-">Using the functions. <br><a class="anchor" aria-label="anchor" href="#using-the-functions-"></a>
</h2>
<p>There are two basic arguments common to all <code>metrica</code>
functions: (i) <code>obs</code>(Oi; observed, a.k.a. actual, measured,
truth, target, label), and (ii) <code>pred</code> (Pi; predicted, a.k.a.
simulated, fitted, modeled, estimate) values. <br></p>
<p>Optional arguments include <code>data</code> that allows to call an
existing data frame containing both observed and predicted vectors, and
<code>tidy</code>, which controls the type of output as a list (tidy =
FALSE) or as a data.frame (tidy = TRUE). <br></p>
<p>For regression, some specific functions for regression also require
to define the axis <code>orientation</code>. For example, the slope of
the symmetric linear regression describing the bivariate scatter (SMA).
<br></p>
</div>
<div class="section level2">
<h2 id="list-of-regression-prediction-performance-metrics-continuous-variables">List of regression prediction performance metrics (continuous
variables) <br><a class="anchor" aria-label="anchor" href="#list-of-regression-prediction-performance-metrics-continuous-variables"></a>
</h2>
<table class="table">
<colgroup>
<col width="5%">
<col width="17%">
<col width="32%">
<col width="23%">
<col width="20%">
</colgroup>
<thead><tr class="header">
<th align="left">#</th>
<th align="left">Metric</th>
<th align="left">Definition</th>
<th align="left">Details</th>
<th align="left">Formula</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">01</td>
<td align="left"><code>RSS</code></td>
<td align="left">Residual sum of squares (a.k.a. as sum of squares)</td>
<td align="left">The sum of squared differences between predicted and
observed values. It represents the base of many error metrics using
squared scale such as the MSE</td>
<td align="left"><span class="math inline">\(RSS = \sum{(O_i -
P_i)^2}\)</span></td>
</tr>
<tr class="even">
<td align="left">02</td>
<td align="left"><code>TSS</code></td>
<td align="left">Total sum of squares</td>
<td align="left">The sum of the squared differences between the
observations and its mean. It is used as a reference error, for example,
to estimate explained variance</td>
<td align="left"><span class="math inline">\(TSS = \sum{(O_i -
\bar{O})^2}\)</span></td>
</tr>
<tr class="odd">
<td align="left">03</td>
<td align="left"><code>var_u</code></td>
<td align="left">Sample variance, uncorrected</td>
<td align="left">The mean of sum of squared differences between values
of an <code>x</code> and its mean (divided by n, not n-1)</td>
<td align="left"><span class="math inline">\(var_u = \frac{1}{n}\sum{(x
- \bar{x})^2}\)</span></td>
</tr>
<tr class="even">
<td align="left">4</td>
<td align="left"><code>uSD</code></td>
<td align="left">Sample standard deviation, uncorrected</td>
<td align="left">The square root of the mean of sum of squared
differences between values of an <code>x</code> and its mean (divided by
n, not n-1)</td>
<td align="left"><span class="math inline">\(uSD =
\sqrt{\frac{1}{n}\sum{(x_i - \bar{x})^2}}\)</span></td>
</tr>
<tr class="odd">
<td align="left">04</td>
<td align="left"><code>B0</code></td>
<td align="left">Intercept of SMA regression</td>
<td align="left">SMA is a symmetric linear regression (invariant
results/interpretation to axis orientation) recommended to describe the
bivariate scatter instead of OLS regression (classic linear model, which
results vary with the axis orientation). B0 could be used to test
agreement along with B1 (H0: B0 = 0, B1 = 1) . Warton et al. (2006)</td>
<td align="left"><span class="math inline">\(\beta_{0_{PO}} = \bar{P} -
\frac{S_P}{S_O} \, ;\, \beta_{0_{OP}} = \bar{O} -
\frac{S_O}{S_P}\)</span></td>
</tr>
<tr class="even">
<td align="left">06</td>
<td align="left"><code>B1</code></td>
<td align="left">Slope of SMA regression</td>
<td align="left">SMA is a symmetric linear regression (invariant
results/interpretation to axis orientation) recommended to describe the
bivariate scatter instead of OLS regression (classic linear model, which
results vary with the axis orientation). B1 could be used to test
isometry of the PO scatter (H0: B1 = 1). B1 also represents the ratio of
standard deviations (So and Sp). Warton et al. (2006)</td>
<td align="left"><span class="math inline">\(\beta_{1_{PO}} =
\frac{S_P}{S_O}\, ;\, \beta_{1_{OP}} = \frac{S_O}{S_P}\)</span></td>
</tr>
<tr class="odd">
<td align="left">07</td>
<td align="left"><code>r</code></td>
<td align="left">Pearson’s correlation coefficient</td>
<td align="left">Strength of linear association between P and O.
However, it measures “precision” but no accuracy. Kirch (2008)</td>
<td align="left"><span class="math inline">\(r =
\frac{{S}_{PO}}{{S}_{P}{S}_{O}}\)</span></td>
</tr>
<tr class="even">
<td align="left">8</td>
<td align="left"><code>R2</code></td>
<td align="left">Coefficient of determination</td>
<td align="left">Strength of linear association between P and O.
However, it measures “precision” but no accuracy</td>
<td align="left"><span class="math inline">\(R^{2} =
\frac{{S^2}_{PO}}{{S^2}_{P}{S^2}_{O}}\)</span></td>
</tr>
<tr class="odd">
<td align="left">09</td>
<td align="left"><code>Xa</code></td>
<td align="left">Accuracy coefficient</td>
<td align="left">Measures accuracy. Used to adjust the precision
measured by <code>r</code> to estimate agreement</td>
<td align="left">$ X_a = $</td>
</tr>
<tr class="even">
<td align="left">10</td>
<td align="left"><code>CCC</code></td>
<td align="left">Concordance correlation coefficient</td>
<td align="left">Tests agreement. It presents both precision (r) and
accuracy (Xa) components. Easy to interpret. Lin (1989)</td>
<td align="left"><span class="math inline">\(CCC = r * X_a\)</span></td>
</tr>
<tr class="odd">
<td align="left">11</td>
<td align="left"><code>MAE</code></td>
<td align="left">Mean Absolute Error</td>
<td align="left">Measures both lack of accuracy and precision in
absolute scale. It keeps the same units than the response variable. Less
sensitive to outliers than the MSE or RMSE. Willmott &amp; Matsuura
(2005)</td>
<td align="left"><span class="math inline">\(MAE = \frac{1}{n} \sum{|O_i
- P_i|}\)</span></td>
</tr>
<tr class="even">
<td align="left">12</td>
<td align="left"><code>RMAE</code></td>
<td align="left">Relative Mean Absolute Error</td>
<td align="left">Normalizes the MAE with respect to the mean of
observations</td>
<td align="left"><span class="math inline">\(RMAE = \frac{\frac{1}{n}
\sum{|O_i - P_i|}}{\bar{O}}\)</span></td>
</tr>
<tr class="odd">
<td align="left">13</td>
<td align="left"><code>MAPE</code></td>
<td align="left">Mean Absolute Percentage Error</td>
<td align="left">Percentage units (independent scale). Easy to explain
and to compare performance across models with different response
variables. Asymmetric and unbounded.</td>
<td align="left"><span class="math inline">\(MAPE =
\frac{1}{n}\sum{|\frac{O_i-P_i}{O_i}|}\)</span></td>
</tr>
<tr class="even">
<td align="left">14</td>
<td align="left"><code>SMAPE</code></td>
<td align="left">Symmetric Mean Absolute Percentage Error</td>
<td align="left">SMAPE tackles the asymmetry issues of MAPE and includes
lower (0%) and upper (200%) bounds. Makridakis (1993)</td>
<td align="left"><span class="math inline">\(SMAPE =
\frac{1}{n}\sum{|\frac{|O_i-P_i|}{(O_i+P_i)/2}|}\)</span></td>
</tr>
<tr class="odd">
<td align="left">15</td>
<td align="left"><code>RAE</code></td>
<td align="left">Relative Absolute Error</td>
<td align="left">RAE normalizes MAE with respect to the total absolute
error. Lower bound at 0 (perfect fit) and no upper bound (infinity)</td>
<td align="left"><span class="math inline">\(RAE =
\frac{\sum{|P_i-O_i|}}{\sum{|O_i-\bar{O}|}}\)</span></td>
</tr>
<tr class="even">
<td align="left">16</td>
<td align="left"><code>RSE</code></td>
<td align="left">Relative Squared Error</td>
<td align="left">Proportion of the total sum of squares that corresponds
to differences between predictions and observations (residual sum of
squares)</td>
<td align="left"><span class="math inline">\(RSE =
\frac{\sum{(P_i-O_i)^2}}{\sum{(O_i-\bar{O})^2}}\)</span></td>
</tr>
<tr class="odd">
<td align="left">17</td>
<td align="left"><code>MBE</code></td>
<td align="left">Mean Bias Error</td>
<td align="left">Main bias error metric. Same units as the response
variable. Related to differences between means of predictions and
observations. Negative values indicate overestimation. Positive values
indicate underestimation. Unbounded. Also known as average error.
Janssen &amp; Heuberger (1995)</td>
<td align="left"><span class="math inline">\(MBE = \frac{1}{n} \sum{(O_i
- P_i)} = \bar{O}-\bar{P}\)</span></td>
</tr>
<tr class="even">
<td align="left">18</td>
<td align="left"><code>PBE</code></td>
<td align="left">Percentage Bias Error</td>
<td align="left">Useful to identify systematic over or under
predictions. Percentage units. As the MBE, PBE negative values indicate
overestimation, while positive values indicate underestimation.
Unbounded. Gupta et al. (1999)</td>
<td align="left"><span class="math inline">\(PBE = 100
\frac{\sum{(P_i-O_i)}}{\sum O_i}\)</span></td>
</tr>
<tr class="odd">
<td align="left">19</td>
<td align="left"><code>PAB</code></td>
<td align="left">Percentage Additive Bias</td>
<td align="left">Percentage of the MSE related to systematic additive
issues on the predictions. Related to difference of the means of
predictions and observations</td>
<td align="left"><span class="math inline">\(PAB =
100\frac{(\bar{O}-\bar{P})^2}{\frac{1}{n} \sum{(P_i -
O_i)^2}}\)</span></td>
</tr>
<tr class="even">
<td align="left">20</td>
<td align="left"><code>PPB</code></td>
<td align="left">Percentage Proportional Bias</td>
<td align="left">Percentage of the MSE related to systematic
proportionality issues on the predictions. Related to slope of
regression line describing the bivariate scatter</td>
<td align="left"><span class="math inline">\(PPB = 100 \frac{S_O
S_P}{\frac{1}{n} \sum{(P_i - O_i)^2}}\)</span></td>
</tr>
<tr class="odd">
<td align="left">21</td>
<td align="left"><code>MSE</code></td>
<td align="left">Mean Squared Error</td>
<td align="left">Comprises both accuracy and precision. High sensitivity
to outliers</td>
<td align="left"><span class="math inline">\(MSE = \frac{1}{n} \sum{(P_i
- O_i)^2}\)</span></td>
</tr>
<tr class="even">
<td align="left">22</td>
<td align="left"><code>RMSE</code></td>
<td align="left">Root Mean Squared Error</td>
<td align="left">Comprises both precision and accuracy, has the same
units than the variable of interest. Very sensitive to outliers</td>
<td align="left"><span class="math inline">\(RMSE = \sqrt{\frac{1}{n}
\sum{(P_i - O_i)^2}}\)</span></td>
</tr>
<tr class="odd">
<td align="left">23</td>
<td align="left"><code>RRMSE</code></td>
<td align="left">Relative Root Mean Squared Error</td>
<td align="left">RMSE normalized by the mean of observations</td>
<td align="left"><span class="math inline">\(RRMSE =
\frac{\sqrt{\frac{1}{n} \sum{(P_i - O_i)^2}}}{\bar{O}}\)</span></td>
</tr>
<tr class="even">
<td align="left">24</td>
<td align="left"><code>RSR</code></td>
<td align="left">Root Mean Standard Deviation Ratio</td>
<td align="left">RMSE normalized by the standard deviation of
observations. Moriasi et al. (2007)</td>
<td align="left"><span class="math inline">\(RSR = \frac{1}{n} \sum{(P_i
- O_i)^2}\)</span></td>
</tr>
<tr class="odd">
<td align="left">25</td>
<td align="left"><code>iqRMSE</code></td>
<td align="left">Inter-quartile Normalized Root Mean Squared Error</td>
<td align="left">RMSE normalized by the interquartile range length
(between percentiles 25th and 75th)</td>
<td align="left"><span class="math inline">\(iqRMSE =
\frac{\sqrt{\frac{1}{n} \sum{(P_i - O_i)^2}}}{[75^{th} percentile -
25^{th} percentile]}\)</span></td>
</tr>
<tr class="even">
<td align="left">26</td>
<td align="left"><code>MLA</code></td>
<td align="left">Mean Lack of Accuracy</td>
<td align="left">Bias component of MSE decomposition. Correndo et
al. (2021)</td>
<td align="left"><span class="math inline">\(MLA = (\bar{O}-\bar{P})^2 +
(S_O - S_P)^2\)</span></td>
</tr>
<tr class="odd">
<td align="left">27</td>
<td align="left"><code>MLP</code></td>
<td align="left">Mean Lack of Precision</td>
<td align="left">Variance component of MSE decomposition. Correndo et
al. (2021)</td>
<td align="left"><span class="math inline">\(MLP = 2 S_O S_P
(1-r)\)</span></td>
</tr>
<tr class="even">
<td align="left">28</td>
<td align="left"><code>RMLA</code></td>
<td align="left">Root Mean Lack of Accuracy</td>
<td align="left">Bias component of MSE decomposition expressed on the
original units of interest. Correndo et al. (2021)</td>
<td align="left"><span class="math inline">\(RMLA =
\sqrt{(\bar{O}-\bar{P})^2 + (S_O - S_P)^2}\)</span></td>
</tr>
<tr class="odd">
<td align="left">29</td>
<td align="left"><code>RMLP</code></td>
<td align="left">Root Mean Lack of Precision</td>
<td align="left">Variance component of MSE decomposition expressed on
the original units of interest. Correndo et al. (2021)</td>
<td align="left"><span class="math inline">\(RMLP = \sqrt{2 S_O S_P
(1-r)}\)</span></td>
</tr>
<tr class="even">
<td align="left">30</td>
<td align="left"><code>PLA</code></td>
<td align="left">Percentage Lack of Accuracy</td>
<td align="left">Percentage of the MSE related to lack of accuracy
(systematic differences) on the predictions. Correndo et al. (2021)</td>
<td align="left"><span class="math inline">\(PLA = 100
\frac{(\bar{O}-\bar{P})^2 + (S_O - S_P)^2}{\frac{1}{n} \sum{(P_i -
O_i)^2} }\)</span></td>
</tr>
<tr class="odd">
<td align="left">31</td>
<td align="left"><code>PLP</code></td>
<td align="left">Percentage Lack of Precision</td>
<td align="left">Percentage of the MSE related to lack of precision
(unsystematic differences) on the predictions. Correndo et
al. (2021)</td>
<td align="left"><span class="math inline">\(PLP = 100 \frac{2 S_O S_P
(1-r)}{\frac{1}{n} \sum{(P_i - O_i)^2} }\)</span></td>
</tr>
<tr class="even">
<td align="left">32</td>
<td align="left"><code>SB</code></td>
<td align="left">Squared Bias</td>
<td align="left">Additive bias component, MSE decomposition. Kobayashi
and Salam (2000)</td>
<td align="left"><span class="math inline">\(SB=(\bar{O}-\bar{P})^2\)</span></td>
</tr>
<tr class="odd">
<td align="left">33</td>
<td align="left"><code>SDSD</code></td>
<td align="left">Product of Standard Deviations</td>
<td align="left">Proportional bias component, MSE decomposition.
Kobayashi and Salam (2000)</td>
<td align="left"><span class="math inline">\(SDSD = S_O
S_P\)</span></td>
</tr>
<tr class="even">
<td align="left">34</td>
<td align="left"><code>LCS</code></td>
<td align="left">Lack of Correlation</td>
<td align="left">Random error component, MSE decomposition. Kobayashi
and Salam (2000)</td>
<td align="left"><span class="math inline">\(LCS = 2 S_P S_O
(1-r)\)</span></td>
</tr>
<tr class="odd">
<td align="left">35</td>
<td align="left"><code>Ue</code></td>
<td align="left">Random error proportion</td>
<td align="left">The Ue estimates the proportion of the total sum of
squares related to the random error (unsystematic error or variance)
following the sum of squares decomposition suggested by Smith and Rose
(1995) also known as Theil’s partial inequalities</td>
<td align="left"><span class="math inline">\(Ue = \frac{2n(1-r)S_O
S_P}{\sum{(O_i-P_i)^2}}\)</span></td>
</tr>
<tr class="even">
<td align="left">36</td>
<td align="left"><code>Uc</code></td>
<td align="left">Lack of Consistency error proportion</td>
<td align="left">The Uc estimates the proportion of the total sum of
squares related to the lack of consistency (proportional bias) following
the sum of squares decomposition suggested by Smith and Rose (1995) also
known as Theil’s partial inequalities</td>
<td align="left"><span class="math inline">\(Uc =
\frac{n(S_O-S_P)^2}{\sum{(O_i-P_i)^2}}\)</span></td>
</tr>
<tr class="odd">
<td align="left">37</td>
<td align="left"><code>Ub</code></td>
<td align="left">Mean Bias error proportion</td>
<td align="left">The Ub estimates the proportion of the total sum of
squares related to the mean bias following the sum of squares
decomposition suggested by Smith and Rose (1995) also known as Theil’s
partial inequalities</td>
<td align="left"><span class="math inline">\(Ub =
\frac{n(\bar{O}-\bar{P})^2}{\sum{(O_i-P_i)^2}}\)</span></td>
</tr>
<tr class="even">
<td align="left">38</td>
<td align="left"><code>NSE</code></td>
<td align="left">Nash and Sutcliffe’s Model Efficiency</td>
<td align="left">Model efficiency using squared residuals normalized by
the variance of observations. Nash and Sutcliffe (1970)</td>
<td align="left"><span class="math inline">\(NSE = 1- \frac{\frac{1}{n}
\sum{(P_i - O_i)^2}}{\frac{1}{n} \sum{(O_i - \bar{O})^2}}\)</span></td>
</tr>
<tr class="odd">
<td align="left">39</td>
<td align="left"><code>E1</code></td>
<td align="left">Absolute Model Efficiency</td>
<td align="left">Model efficiency. Modification of NSE using absolute
residuals instead of squared residuals. Legates and McCabe (1999)</td>
<td align="left"><span class="math inline">\(E1 = 1- \frac{\sum{|P_i -
O_i|}}{\sum{|O_i - \bar{O}|}}\)</span></td>
</tr>
<tr class="even">
<td align="left">40</td>
<td align="left"><code>Erel</code></td>
<td align="left">Relative Model Efficiency</td>
<td align="left">Compared to the NSE, the Erel is suggested as more
sensitive to systematic over- or under-predictions. Krause et
al. (2005)</td>
<td align="left"><span class="math inline">\(Erel = 1-
\frac{\sum{(\frac{P_i - O_i}{Oi})^2}}{\sum{(\frac{O_i -
\bar{O}}{Oi})^2}}\)</span></td>
</tr>
<tr class="odd">
<td align="left">41</td>
<td align="left"><code>KGE</code></td>
<td align="left">Kling-Gupta Model Efficiency</td>
<td align="left">Model efficiency with accuracy, precision, and
consistency components. Kling et al. (2012)</td>
<td align="left"><span class="math inline">\(KGE = 1- \sqrt{(r-1)^2+
(\frac{S_P}{S_O}-1)^2+(\frac{\bar{P}}{\bar{O}}-1)^2}\)</span></td>
</tr>
<tr class="even">
<td align="left">42</td>
<td align="left"><code>d</code></td>
<td align="left">Index of Agreement</td>
<td align="left">Measures accuracy and precision using squared
residuals. Dimensionless (normalized). Bounded [0;1]. Asymmetric
Willmott (1981)</td>
<td align="left"><span class="math inline">\(d = 1- \frac{\sum{(O_i -
P_i)^2}}{\sum{(|O_i - \bar{P}| + |P_i - \bar{O}|})^2}\)</span></td>
</tr>
<tr class="odd">
<td align="left">43</td>
<td align="left"><code>d1</code></td>
<td align="left">Modified Index of Agreement</td>
<td align="left">Measures accuracy and precision using absolute
residuals(1). Dimensionless (normalized). Bounded [0;1]. Asymmetric
Willmott et al. (1985)</td>
<td align="left"><span class="math inline">\(d1 = 1- \frac{\sum{|O_i -
P_i}|}{\sum{(|O_i - \bar{O}| + |P_i - \bar{O}|})}\)</span></td>
</tr>
<tr class="even">
<td align="left">44</td>
<td align="left"><code>d1r</code></td>
<td align="left">Refined Index of Agreement</td>
<td align="left">Refines d1 by a modification on the denominator
(potential error) to normalize absolute error. Willmott et
al. (2012)</td>
<td align="left"><span class="math inline">\(d1r = 1- \frac{\sum{|O_i -
P_i}|}{2\sum{|O_i - \bar{O}|}}\)</span></td>
</tr>
<tr class="odd">
<td align="left">45</td>
<td align="left"><code>RAC</code></td>
<td align="left">Robinson’s Agreement Coefficient</td>
<td align="left">RAC measures both accuracy and precision (general
agreement). Dimensionless (normalized). Bounded [0;1]. Symmetric.
Robinson (1957; 1959)</td>
<td align="left">
<span class="math inline">\(RAC = 1- \frac{\sum{(O_i -
Z_i})^2 + \sum{(P_i - Z_i})^2}{\sum{(O_i - \bar{Z})^2 + \sum{(P_i -
\bar{Z})^2} } }\)</span> <br> where <br><span class="math inline">\(Zi = \frac{O_i + P_i}{2}; \bar{Z} = \bar{O} +
\bar{P}\)</span>
</td>
</tr>
<tr class="even">
<td align="left">46</td>
<td align="left"><code>AC</code></td>
<td align="left">Ji and Gallo’s Agreement Coefficient</td>
<td align="left">AC measures both accuracy and precision (general
agreement). Dimensionless (normalized). Positively bounded
[-infinity;1]. Symmetric. Ji and Gallo (2006)</td>
<td align="left"><span class="math inline">\(AC = 1 -
\frac{\sum{(O_i-P_i)^2}}{\sum{[(|\bar{P}-\bar{O}|+|O_i-\bar{O}|)(|\bar{P}-\bar{O}|+|P_i-\bar{P}|)]}}\)</span></td>
</tr>
<tr class="odd">
<td align="left">47</td>
<td align="left"><code>lambda</code></td>
<td align="left">Duveiller’s Lambda Coefficient</td>
<td align="left">
<code>lambda</code> measures both accuracy and
precision. Dimensionless (normalized). Bounded [-1;1]. Symmetric.
Equivalent to CCC when <code>r</code> is greater or equal to 0.
Duveiller et al. (2016)</td>
<td align="left">
<span class="math inline">\(\lambda = 1 -
\frac{\frac{1}{n}\sum(O_i-P_i)^2}{S^2_P+S^2_O+(\bar{O}-\bar{P})^2+
n^{-1}k}\)</span> <br> where <br><span class="math inline">\(k =
0\,\, if\,\, r \geq{0}\)</span>, <br> otherwise <br><span class="math inline">\(k =
2|\sum[(O_i-\bar{O})(P_i-\bar{P})]|\)</span>
</td>
</tr>
<tr class="even">
<td align="left">48</td>
<td align="left"><code>dcorr</code></td>
<td align="left">Distance correlation</td>
<td align="left">Measures the dependency between to random vectors.
Compared to Pearson’s <code>r</code>, it offers the advantage of
considering both linear and nonlinear association patterns. It is based
on a matrix of centered Euclidean distances compared to the distance of
many shuffles of the data. It is dimensionless, bounded [0;1], and
symmetric. <code>dcorr = 0</code> characterizes independence between
vectors. The closest to 1 the better. A disadvantage for the
predicted-observed case is that values can be negatively correlated but
producing a <code>dcorr</code> close to 1. Székely (2007)</td>
<td align="left">
<span class="math inline">\(dcorr =
\sqrt{\frac{\mathcal{V}^2_n~(\mathbf{P,O})}{ {\sqrt{\mathcal{V}^2_n
(\mathbf{P}) \mathcal{V}^2_n(\mathbf{O})} } }}\)</span> See Székely
(2007) for full details</td>
</tr>
<tr class="odd">
<td align="left">49</td>
<td align="left"><code>MIC</code></td>
<td align="left">Maximal Information Coefficient</td>
<td align="left">Measures association between two variables based on
“binning” (a.k.a. data bucketing) to reduce the influence of small
observation errors. It is based on the “mutual information” concept of
information theory, which measures the mutual dependence between two
variables. It is dimensionless (normalized), bounded [0;1], and
symmetric. Reshef et al. (2011)</td>
<td align="left">
<span class="math inline">\(MIC(D) = max_{PO&lt;B(n)}
M(D)_{X,Y} = max_{PO&lt;B(n)}
\frac{I^{(D,P,O)}}{log(\min{P,O})}\)</span> <br> where <span class="math inline">\(B(n) = n^{\alpha}\)</span> is the search-grid
size, <span class="math inline">\(I^{(D,P,O)}\)</span> is the maximum
mutual information over all grids P-by-O, of the distribution induced by
<span class="math inline">\(D\)</span> on a grid having P and O bins
(where the probability mass on a cell of the grid is the fraction of
points of D falling in that cell). <br> See Reshef et al. 2011, for
full details.</td>
</tr>
<tr class="even">
<td align="left">50</td>
<td align="left"><code>MASE</code></td>
<td align="left">Mean Absolute Scaled Error</td>
<td align="left">The <code>MASE</code> is especially well suited for
time series predictions, as it scales (or normalize) the error based on
<em>in-sample</em> MAE from the naive forecast method (a.k.a. random
walk). It is dimensionless (normalized) and symmetric. The reference
score is MASE = 1, which indicates that the model performs the same than
a naive forecast (error with respect to previous historical
observation). MASE &lt;1 indicates that the model performs better than
naive forecast, and MASE &gt; 1 indicates a bad performance of the
predictions. See Hyndman &amp; Koehler (2006)</td>
<td align="left"><span class="math inline">\(MASE =
\frac{1}{n}(\frac{|O_i-P_i|}{ \frac{1}{T-1} \sum^T_{t=2}~|O_t - O_{t-1}|
})\)</span></td>
</tr>
</tbody>
</table>
<p><br></p>
</div>
<div class="section level2">
<h2 id="references">References: <br><a class="anchor" aria-label="anchor" href="#references"></a>
</h2>
<ol style="list-style-type: decimal">
<li><p>Correndo et al. (2021). Revisiting linear regression to test
agreement in continuous predicted-observed datasets. <em>Agric. Syst.
192, 103194.</em> <br></p></li>
<li><p>Duveiller et al. (2016). Revisiting the concept of a symmetric
index of agreement for continuous datasets. <em>Sci. Rep. 6, 1-14.</em>
<br></p></li>
<li><p>Gupta et al. (1999). Status of automatic calibration for
hydrologic models: Comparison with multilevel expert calibration. <em>J.
Hydrologic Eng. 4(2): 135-143.</em> <br></p></li>
<li><p>Janssen &amp; Heuberger (1995). Calibration of process-oriented
models. <em>Ecol. Modell. 83, 55-66.</em> <br></p></li>
<li><p>Ji &amp; Gallo (2006). An agreement coefficient for image
comparison. <em>Photogramm. Eng. Remote Sensing 7, 823–833.</em>
<br></p></li>
<li><p>Kling et al. (2012). Runoff conditions in the upper Danube basin
under an ensemble of climate change scenarios. <em>J. Hydrol., 424-425,
264-277.</em> <br></p></li>
<li><p>Kirch (2008). Pearson’s Correlation Coefficient. <em>In: Kirch W.
(eds) Encyclopedia of Public Health. Springer, Dordrecht.</em>
<br></p></li>
<li><p>Krause et al. (2005). Comparison of different efficiency criteria
for hydrological model assessment. <em>Adv. Geosci. 5, 89–97.</em>
<br></p></li>
<li><p>Kobayashi &amp; Salam (2000). Comparing simulated and measured
values using mean squared deviation and its components. <em>Agron. J.
92, 345–352.</em> <br></p></li>
<li><p>Legates &amp; McCabe (1999). Evaluating the use of
“goodness-of-fit” measures in hydrologic and hydroclimatic model
validation. <em>Water Resour. Res.</em> <br></p></li>
<li><p>Lin (1989). A concordance correlation coefficient to evaluate
reproducibility. <em>Biometrics 45 (1), 255–268.</em> <br></p></li>
<li><p>Makridakis (1993). Accuracy measures: theoretical and practical
concerns. <em>Int. J. Forecast. 9, 527-529.</em> <br></p></li>
<li><p>Moriasi et al. (2007). Model Evaluation Guidelines for Systematic
Quantification of Accuracy in Watershed Simulations. <em>Trans. ASABE
50, 885–900.</em> <br></p></li>
<li><p>Nash &amp; Sutcliffe (1970). River flow forecasting through
conceptual models part I - A discussion of principles. <em>J. Hydrol.
10(3), 292-290.</em> <br></p></li>
<li><p>Robinson (1957). The statistical measurement of agreement.
<em>Am. Sociol. Rev. 22(1), 17-25.</em> <br></p></li>
<li><p>Robinson (1959). The geometric interpretation of agreement.
<em>Am. Sociol. Rev. 24(3), 338-345.</em> <br></p></li>
<li><p>Smith &amp; Rose (1995). Model goodness-of-fit analysis using
regression and related techniques. <em>Ecol. Model. 77, 49–64.</em>
<br></p></li>
<li><p>Warton et al. (2006). Bivariate line-fitting methods for
allometry. <em>Biol. Rev. Camb. Philos. Soc. 81, 259–291.</em>
<br></p></li>
<li><p>Willmott (1981). On the validation of models. <em>Phys. Geogr. 2,
184–194.</em> <br></p></li>
<li><p>Willmott et al. (1985). Statistics for the evaluation and
comparison of models. <em>J. Geophys. Res. 90, 8995.</em> <br></p></li>
<li><p>Willmott &amp; Matsuura (2005). Advantages of the mean absolute
error (MAE) over the root mean square error (RMSE) in assessing average
model performance. <em>Clim. Res. 30, 79–82.</em> <br></p></li>
<li><p>Willmott et al. (2012). A refined index of model performance.
<em>Int. J. Climatol. 32, 2088–2094.</em> <br></p></li>
<li><p>Yang et al. (2014). An evaluation of the statistical methods for
testing the performance of crop models with observed data. <em>Agric.
Syst. 127, 81-89.</em> <br></p></li>
<li><p>Szekely, G.J., Rizzo, M.L., and Bakirov, N.K. (2007). Measuring
and testing dependence by correlation of distances. <em>Annals of
Statistics, Vol. 35(6): 2769-2794.</em> <br></p></li>
<li><p>Reshef, D., Reshef, Y., Finucane, H., Grossman, S., McVean, G.,
Turnbaugh, P., Lander, R., Mitzenmacher, M., and Sabeti, P. (2011).
Detecting novel associations in large datasets. <em>Science 334,
6062</em>. </p></li>
<li><p>Hyndman, R.J., Koehler, A.B. (2006). Another look at measures of
forecast accuracy. <em>Int. J. Forecast</em> <br></p></li>
</ol>
</div>
  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p></p>
<p>Developed by Adrian A. Correndo, Adrian A. Correndo, Luiz H. Moro Rosso, Rai Schwalbert, Carlos Hernandez, Leonardo M. Bastos, Luciana Nieto, Dean Holzworth, Ignacio A. Ciampitti.</p>
</div>

<div class="pkgdown-footer-right">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.7.</p>
</div>

    </footer>
</div>

  

  

  </body>
</html>
