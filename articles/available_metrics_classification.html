<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="metrica">
<title>Classification performance metrics and indices • metrica</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.2.2/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.2.2/bootstrap.bundle.min.js"></script><link href="../deps/Barlow_Condensed-0.4.5/font.css" rel="stylesheet">
<link href="../deps/Ubuntu_Mono-0.4.5/font.css" rel="stylesheet">
<link href="../deps/Barlow_Semi_Condensed-0.4.5/font.css" rel="stylesheet">
<!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- bootstrap-toc --><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@v1.0.1/dist/bootstrap-toc.min.js" integrity="sha256-4veVQbu7//Lk5TSmc7YV48MxtMy98e26cf5MrgZYnwo=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Classification performance metrics and indices">
<meta property="og:description" content="metrica">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-dark navbar-expand-lg bg-primary"><div class="container">
    
    <a class="navbar-brand me-2" href="../index.html">metrica</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">2.0.3</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item">
  <a class="nav-link" href="../reference/index.html">
    <span class="fa fa-gears"></span>
     
    Functions
  </a>
</li>
<li class="nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown--metrics">
    <span class="fa fa-ruler"></span>
     
    Metrics
  </a>
  <div class="dropdown-menu" aria-labelledby="dropdown--metrics">
    <a class="dropdown-item" href="../articles/regression_case.html">Regression performance</a>
    <a class="dropdown-item" href="../articles/regression_case.html">Classification performance</a>
  </div>
</li>
<li class="nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown--tutorials">
    <span class="fa fa-paperclip"></span>
     
    Tutorials
  </a>
  <div class="dropdown-menu" aria-labelledby="dropdown--tutorials">
    <a class="dropdown-item" href="../articles/regression_case.html">Regression</a>
    <a class="dropdown-item" href="../articles/regression_case.html">Classification</a>
    <a class="dropdown-item" href="../articles/apsim_open.html">Import APSIM files</a>
  </div>
</li>
<li class="nav-item">
  <a class="nav-link" href="../articles/Cheatsheet.html">
    <span class="fa fa-note-sticky"></span>
     
    Cheatsheet
  </a>
</li>
<li class="nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown--more">
    <span class="fa fa-plus"></span>
     
    More
  </a>
  <div class="dropdown-menu" aria-labelledby="dropdown--more">
    <a class="dropdown-item" href="../articles/JOSS_publication.html">JOSS publication</a>
    <a class="dropdown-item" href="../articles/Shinyapp.html">Shinyapp</a>
  </div>
</li>
<li class="nav-item">
  <a class="nav-link" href="../news/index.html">
    <span class="fa fa-newspaper"></span>
     
    News
  </a>
</li>
      </ul>
<form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../search.json" id="search-input" placeholder="Search for" autocomplete="off">
</form>

      <ul class="navbar-nav">
<li class="nav-item">
  <a class="external-link nav-link" href="https://github.com/adriancorrendo/metrica/">
    <span class="fa fa-github"></span>
     
  </a>
</li>
<li class="nav-item">
  <a class="external-link nav-link" href="https://adriancorrendo.github.io/">
    <span class="fa fa-user"></span>
     
  </a>
</li>
      </ul>
</div>

    
  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="" class="logo" alt=""><h1>Classification performance metrics and indices</h1>
                        <h4 data-toc-skip class="author">Luciana Nieto
&amp; Adrian Correndo</h4>
            
            <h4 data-toc-skip class="date">2023-04-12</h4>
      
      <small class="dont-index">Source: <a href="https://github.com/adriancorrendo/metrica/blob/HEAD/vignettes/available_metrics_classification.Rmd" class="external-link"><code>vignettes/available_metrics_classification.Rmd</code></a></small>
      <div class="d-none name"><code>available_metrics_classification.Rmd</code></div>
    </div>

    
    
<div class="section level2">
<h2 id="description">Description <br><a class="anchor" aria-label="anchor" href="#description"></a>
</h2>
<p>The <strong>metrica</strong> package compiles +80 functions to assess
regression (continuous) and classification (categorical) prediction
performance from multiple perspectives. <br></p>
<p>For classification (binomial and multinomial) tasks, it includes a
function to visualize the confusion matrix using ggplot2, and 27
functions of prediction scores including: accuracy, error rate,
precision, recall, specificity, balanced accuracy (balacc), F-score
(fscore), adjusted F-score (agf), G-mean (gmean), Bookmaker Informedness
(bmi, a.k.a. Youden’s J-index), Markedness (deltaP), Matthews
Correlation Coefficient (mcc), Cohen’s Kappa (khat), negative predictive
value (npv), positive and negative likelihood ratios (posLr, negLr),
diagnostic odds ratio (dor), prevalence (preval), prevalence threshold
(preval_t), critical success index (csi, a.k.a. threat score), false
positive rate (FPR), false negative rate (FNR), false detection rate
(FDR), false omission rate (FOR), and area under the ROC curve
(AUC_roc). <br></p>
<p>For supervised models, always keep in mind the concept of
“cross-validation” since predicted values should ideally come from
out-of-bag samples (unseen by training sets) to avoid overestimation of
the prediction performance. <br></p>
</div>
<div class="section level2">
<h2 id="using-the-functions">Using the functions <br><a class="anchor" aria-label="anchor" href="#using-the-functions"></a>
</h2>
<p>There are two basic arguments common to all <code>metrica</code>
functions: (i) <code>obs</code>(Oi; observed, a.k.a. actual, measured,
truth, target, label), and (ii) <code>pred</code> (Pi; predicted, a.k.a.
simulated, fitted, modeled, estimate) values. <br></p>
<p>Optional arguments include <code>data</code> that allows to call an
existing data frame containing both observed and predicted vectors, and
<code>tidy</code>, which controls the type of output as a list (tidy =
FALSE) or as a data.frame (tidy = TRUE). <br></p>
<p>For binary classification (two classes), functions also require to
check the <code>pos_level</code> arg., which indicates the alphanumeric
order of the “positive level”. Normally, the most common binary
denominations are c(0,1), c(“Negative”, “Positive”), c(“FALSE”, “TRUE”),
so the default pos_level = 2 (1, “Positive”, “TRUE”). However, other
cases are also possible, such as c(“Crop”, “NoCrop”) for which the user
needs to specify pos_level = 1. <br></p>
<p>For multiclass classification tasks, some functions present the
<code>atom</code> arg. (logical TRUE / FALSE), which controls the output
to be an overall average estimate across all classes, or a class-wise
estimate. For example, user might be interested in obtaining estimates
of precision and recall for each possible class of the prediction.
<br></p>
</div>
<div class="section level2">
<h2 id="list-of-classification-metrics-categorical-variables">List of classification metrics* (categorical variables) <br><a class="anchor" aria-label="anchor" href="#list-of-classification-metrics-categorical-variables"></a>
</h2>
<p><em>Note: All classification functions automatically recognize the
number of classes and adjust estimations for binary or multiclass cases.
However, for binary classification tasks, the user would need to check
the alphanumeric order of the level considered as positive. By default
“pos_level = 2” based on the most common denominations being c(0,1),
c(“Negative”,“Positive”), c(“TRUE”, “FALSE”).</em> <br></p>
<table class="table">
<colgroup>
<col width="6%">
<col width="18%">
<col width="31%">
<col width="21%">
<col width="21%">
</colgroup>
<thead><tr class="header">
<th align="left">#</th>
<th align="left">Metric</th>
<th align="left">Definition</th>
<th align="left">Details</th>
<th align="left">Formula</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">1</td>
<td align="left"><code>accuracy</code></td>
<td align="left">Accuracy</td>
<td align="left">It is the most commonly used metric to evaluate
classification quality. It represents the number of corrected classified
cases with respect to all cases. However, be aware that this metric does
not cover all aspects about classification quality. When classes are
uneven in number, it may not be a reliable metric.</td>
<td align="left"><span class="math inline">\(accuracy =
\frac{TP+TN}{TP+FP+TN+FN}\)</span></td>
</tr>
<tr class="even">
<td align="left">2</td>
<td align="left"><code>error_rate</code></td>
<td align="left">Error Rate</td>
<td align="left">It represents the complement of accuracy. It could vary
between 0 and 1. Being 0 the best and 1 the worst</td>
<td align="left"><span class="math inline">\(error~rate =
\frac{FP+FN}{TP+FP+TN+FN}\)</span></td>
</tr>
<tr class="odd">
<td align="left">3</td>
<td align="left">
<code>precision</code>, <code>ppv</code>
</td>
<td align="left">Precision</td>
<td align="left">Also known as positive predictive value (ppv), it
represents the proportion of well classified cases with respect to the
total of cases predicted with a given class (multinomial) or the true
class (binomial)</td>
<td align="left"><span class="math inline">\(precision = \frac{TP}{TP +
FP}\)</span></td>
</tr>
<tr class="even">
<td align="left">4</td>
<td align="left">
<code>recall</code>, <code>sensitivity</code>,
<code>TPR</code>, <code>hitrate</code>
</td>
<td align="left">Recall</td>
<td align="left">Also known as sensitivity, hit rate, or true positive
rate (TPR) for binary cases. It represents the proportion of well
predicted cases with respect to the total number of observed cases for a
given class (multinomial) or the positive class (binomial)</td>
<td align="left"><span class="math inline">\(recall = \frac{TP}{P} = 1 -
FNR\)</span></td>
</tr>
<tr class="odd">
<td align="left">5</td>
<td align="left">
<code>specificity</code>, <code>selectivity</code>,
<code>TNR</code>
</td>
<td align="left">Specificity</td>
<td align="left">Also known as selectivity or true negative rate (TNR).
It represents the proportion of well classified negative values with
respect to the total number of actual negatives</td>
<td align="left"><span class="math inline">\(specificity = \frac{TN}{N}
= 1 - FPR\)</span></td>
</tr>
<tr class="even">
<td align="left">6</td>
<td align="left"><code>balacc</code></td>
<td align="left">Balanced Accuracy</td>
<td align="left">This metric is especially useful when the number of
observations across classes is imbalanced</td>
<td align="left"><span class="math inline">\(b.accuracy = \frac{recall +
specificity}{2}\)</span></td>
</tr>
<tr class="odd">
<td align="left">7</td>
<td align="left"><code>fscore</code></td>
<td align="left">F-score</td>
<td align="left">F1-score, F-measure</td>
<td align="left"><span class="math inline">\(fscore = \frac{(1 + B ^ 2)
* precision * recall}{(B ^ 2 * precision) + recall)}\)</span></td>
</tr>
<tr class="even">
<td align="left">8</td>
<td align="left"><code>agf</code></td>
<td align="left">Adjusted F-score</td>
<td align="left">The agf adjusts the fscore for datasets with imbalanced
classes</td>
<td align="left">
<span class="math inline">\(agf = \sqrt{F_2 *
invF_{0.5}}\)</span>, where <span class="math inline">\(F_2 = 5 *
\frac{recall~*~precision}{(4*recall)~+~precision}\)</span>, and <span class="math inline">\(invF_{0.5} = (\frac{5}{4}) *
\frac{recall~*~precision}{(0.5^2 ~*~ recall)~+~precision}\)</span>
</td>
</tr>
<tr class="odd">
<td align="left">9</td>
<td align="left"><code>gmean</code></td>
<td align="left">G-mean</td>
<td align="left">The Geometric Mean (gmean) is a measure that considers
a balance between the performance of both majority and minority classes.
The higher the value the lower the risk of over-fitting of negative and
under-fitting of positive classes</td>
<td align="left"><span class="math inline">\(gmean =
\sqrt{recall~*~specificity}\)</span></td>
</tr>
<tr class="even">
<td align="left">10</td>
<td align="left"><code>khat</code></td>
<td align="left">K-hat or Cohen’s Kappa Coefficient</td>
<td align="left">The khat is considered a more robust metric than the
classic <code>accuracy</code>. It normalizes the accuracy by the
possibility of agreement by chance. It is positively bounded to 1, but
it is not negatively bounded. The closer to 1, the better the
classification quality</td>
<td align="left"><span class="math inline">\(khat = \frac{2 * (TP * TN -
FN * FP)}{(TP+FP) * (FP+TN) + (TP+FN) * (FN + TN)}\)</span></td>
</tr>
<tr class="odd">
<td align="left">11</td>
<td align="left">
<code>mcc</code>, <code>phi_coef</code>
</td>
<td align="left">Matthews Correlation Coefficient</td>
<td align="left">Also known as phi-coefficient. It is particularly
useful when the number of observations belonging to each class is
uneven. It varies between 0-1, being 0 the worst and 1 the best.
Currently, the mcc estimation is only available for binary cases (two
classes)</td>
<td align="left"><span class="math inline">\(mcc = \frac{TP * TN - FP *
FN}{\sqrt{(TP+FP) * (TP+FN) * (TN+FP) * (TN+FN)}}\)</span></td>
</tr>
<tr class="even">
<td align="left">12</td>
<td align="left"><code>fmi</code></td>
<td align="left">Fowlkes-Mallows Index</td>
<td align="left">The fmi is a metric that measures the similarity
between two clusters (predicted and observed). It is equivalent to the
square root of the product between precision (PPV) and recall (TPR). It
varies between 0-1, being 0 the worst and 1 the best.</td>
<td align="left"><span class="math inline">\(fmi = \sqrt{precision *
recall} = \sqrt{PPV * TPR}\)</span></td>
</tr>
<tr class="odd">
<td align="left">13</td>
<td align="left">
<code>bmi</code>, <code>jindex</code>
</td>
<td align="left">Informedness</td>
<td align="left">Also known as the Bookmaker Informedness, or as the
Youden’s J-index. It is a suitable metric when the number of cases for
each class is uneven. It varies between</td>
<td align="left"><span class="math inline">\(bmi = recall + specificity
-1 = TPR + TNR - 1 = \frac{FP+FN}{TP+FP+TN+FN}\)</span></td>
</tr>
<tr class="even">
<td align="left">14</td>
<td align="left"><code>posLr</code></td>
<td align="left">Positive Likelihood Ratio</td>
<td align="left">The posLr, also known as LR(+) represents the odds of
obtaining a positive prediction for actual positives.</td>
<td align="left"><span class="math inline">\(posLr =
\frac{recall}{1+specificity} = \frac{TPR}{FPR}\)</span></td>
</tr>
<tr class="odd">
<td align="left">15</td>
<td align="left"><code>negLr</code></td>
<td align="left">Negative Likelihood Ratio</td>
<td align="left">The negLr, also known as LR(-) indicates the odds of
obtaining a negative prediction for actual positives (or non-negatives
in multiclass) relative to the probability of actual negatives of
obtaining a negative prediction</td>
<td align="left"><span class="math inline">\(negLr =
\frac{1-recall}{specificity} = \frac{FNR}{TNR}\)</span></td>
</tr>
<tr class="even">
<td align="left">16</td>
<td align="left"><code>dor</code></td>
<td align="left">Diagnostic Odds Ratio</td>
<td align="left">The dor is a metric summarizing the effectiveness of
classification. It represents the odds of a positive case obtaining a
positive prediction result with respect to the odds of actual negatives
obtaining a positive result</td>
<td align="left"><span class="math inline">\(dor =
\frac{posLr}{negLr}\)</span></td>
</tr>
<tr class="odd">
<td align="left">17</td>
<td align="left"><code>npv</code></td>
<td align="left">Negative predictive Value</td>
<td align="left">It represents the complement of accuracy. It could vary
between 0 and 1. Being 0 the best and 1 the worst</td>
<td align="left"><span class="math inline">\(npv = \frac{TP}{PP} =
\frac{TP}{TP + FP}\)</span></td>
</tr>
<tr class="even">
<td align="left">18</td>
<td align="left"><code>FPR</code></td>
<td align="left">False Positive Rate</td>
<td align="left">It represents the complement of
<code>specificity</code>. It could vary between 0 and 1. The lower the
better.</td>
<td align="left"><span class="math inline">\(FPR = 1 - specificity = 1 -
TNR = \frac{FP}{N}\)</span></td>
</tr>
<tr class="odd">
<td align="left">19</td>
<td align="left"><code>FNR</code></td>
<td align="left">False Negative Rate</td>
<td align="left">It represents the complement of <code>recall</code>. It
could vary between 0 and 1. The lower the better.</td>
<td align="left"><span class="math inline">\(FNR = 1 - recall = 1 - TPR
= \frac{FN}{P}\)</span></td>
</tr>
<tr class="even">
<td align="left">20</td>
<td align="left"><code>FDR</code></td>
<td align="left">False Detection Rate</td>
<td align="left">It represents the complement of <code>precision</code>
(or positive predictive value -<code>ppv</code>-). It could vary between
0 and 1, being 0 the best and 1 the worst</td>
<td align="left"><span class="math inline">\(FDR = 1 - precision =
\frac{FP}{PP} = \frac{FP}{TP + FP}\)</span></td>
</tr>
<tr class="odd">
<td align="left">21</td>
<td align="left"><code>FOR</code></td>
<td align="left">False Omission Rate</td>
<td align="left">It represents the complement of the <code>npv</code>.
It could vary between 0 and 1, being 0 the best and 1 the worst</td>
<td align="left"><span class="math inline">\(FOR = 1 - npv =
\frac{FN}{PN} = \frac{FN}{TN + FN}\)</span></td>
</tr>
<tr class="even">
<td align="left">22</td>
<td align="left"><code>preval</code></td>
<td align="left">Error Rate</td>
<td align="left">It represents the complement of accuracy. It could vary
between 0 and 1. Being 0 the best and 1 the worst</td>
<td align="left"><span class="math inline">\(error~rate =
\frac{FP+FN}{TP+FP+TN+FN}\)</span></td>
</tr>
<tr class="odd">
<td align="left">23</td>
<td align="left"><code>preval_t</code></td>
<td align="left">Error Rate</td>
<td align="left">It represents the complement of accuracy. It could vary
between 0 and 1. Being 0 the best and 1 the worst</td>
<td align="left"><span class="math inline">\(error~rate =
\frac{FP+FN}{TP+FP+TN+FN}\)</span></td>
</tr>
<tr class="even">
<td align="left">24</td>
<td align="left">
<code>csi</code>, <code>jaccardindex</code>
</td>
<td align="left">Critical Success Index</td>
<td align="left">The <code>csi</code> is also known as the threat score
(TS) or Jaccard’s Index. It could vary between 0 and 1, being 0 the
worst and 1 the best</td>
<td align="left"><span class="math inline">\(csi =
\frac{TP}{TP+FP+TN}\)</span></td>
</tr>
<tr class="odd">
<td align="left">25</td>
<td align="left">
<code>deltap</code>, <code>mk</code>
</td>
<td align="left">Markedness or deltap</td>
<td align="left">The <code>deltap</code> (a.k.a. Markedness
-<code>mk</code>-) is a metric that quantifies the probability that a
condition is marked by the predictor with respect to a random
chance</td>
<td align="left"><span class="math inline">\(deltap = precision+npv-1 =
PPV + NPV -1\)</span></td>
</tr>
<tr class="even">
<td align="left">26</td>
<td align="left"><code>AUC_roc</code></td>
<td align="left">Area Under the Curve</td>
<td align="left">The <code>AUC_roc</code> estimates the area under the
receiving operator characteristic curve following the trapezoid
approach. It bounded between 0 and 1. The closet to 1 the better.
AUC_roc = 0.5 means the models predictions are the same than a random
classifier.</td>
<td align="left"><span class="math inline">\(AUC_{roc} = precision+npv-1
= PPV + NPV -1\)</span></td>
</tr>
</tbody>
</table>
<p><br></p>
<p><strong>List of additional abbreviations:</strong></p>
<p>P = positive (true + false)</p>
<p>N = negative (true + false)</p>
<p>TP = true positive</p>
<p>TN = true negative</p>
<p>FP = false positive</p>
<p>FN = false negative</p>
<p>TPR = true positive rate</p>
<p>TNR = true negative rate</p>
<p>FPR = false positive rate</p>
<p>FNR = false negative rate</p>
<p>ppv = positive predictive value</p>
<p>B = coefficient B (a.k.a. beta) indicating the weight to be applied
to the estimation of <code>fscore</code> (as <span class="math inline">\(B^2\)</span>).</p>
</div>
<div class="section level2">
<h2 id="references">References: <br><a class="anchor" aria-label="anchor" href="#references"></a>
</h2>
<ol style="list-style-type: decimal">
<li><p>Ting K.M. (2017). Confusion Matrix. <em>In: Sammut C., Webb G.I.
(eds) Encyclopedia of Machine Learning and Data Mining. Springer,
Boston, MA.</em> </p></li>
<li><p>Accuracy. (2017). <em>In: Sammut C., Webb G.I. (eds) Encyclopedia
of Machine Learning and Data Mining</em> <em>. Springer, Boston,
MA.</em> </p></li>
<li><p>García, V., Mollineda, R.A., Sánchez, J.S. (2009). Index of
Balanced Accuracy: A Performance Measure for Skewed Class Distributions.
<em>In: Araujo, H., Mendonça, A.M., Pinho, A.J., Torres, M.I. (eds)
Pattern Recognition and Image Analysis. IbPRIA 2009. Lecture Notes in
Computer Science, vol 5524. Springer-Verlag Berlin Heidelberg.</em>
</p></li>
<li><p>Ting K.M. (2017). Precision and Recall. <em>In: Sammut C., Webb
G.I. (eds) Encyclopedia of Machine Learning and Data Mining. Springer,
Boston, MA.</em> </p></li>
<li><p>Sensitivity. (2017). <em>In: Sammut C., Webb G.I. (eds)
Encyclopedia of Machine Learning and Data Mining. Springer, Boston,
MA.</em> </p></li>
<li><p>Ting K.M. (2017). Sensitivity and Specificity. <em>In: Sammut C.,
Webb G.I. (eds) Encyclopedia of Machine Learning and Data Mining.
Springer, Boston, MA.</em> </p></li>
<li><p>Trevethan, R. (2017). Sensitivity, Specificity, and Predictive
Values: Foundations, Pliabilities, and Pitfalls in Research and
Practice. <em>Front. Public Health 5:307</em> </p></li>
<li><p>Goutte, C., Gaussier, E. (2005). A Probabilistic Interpretation
of Precision, Recall and F-Score, with Implication for Evaluation.
<em>In: D.E. Losada and J.M. Fernandez-Luna (Eds.): ECIR 2005. Advances
in Information Retrieval LNCS 3408, pp. 345–359, 2. Springer-Verlag
Berlin Heidelberg.</em> </p></li>
<li><p>Maratea, A., Petrosino, A., Manzo, M. (2014). Adjusted-F measure
and kernel scaling for imbalanced data learning. <em>Inf. Sci. 257:
331-341.</em> </p></li>
<li><p>De Diego, I.M., Redondo, A.R., Fernández, R.R., Navarro, J.,
Moguerza, J.M. (2022). General Performance Score for classification
problems. <em>Appl. Intell. (2022).</em> </p></li>
<li><p>Fowlkes, Edward B; Mallows, Colin L (1983). A method for
comparing two hierarchical clusterings. <em>Journal of the American
Statistical Association. 78 (383): 553–569.</em> </p></li>
<li><p>Chicco, D., Jurman, G. (2020). The advantages of the Matthews
correlation coefficient (MCC) over F1 score and accuracy in binary
classification evaluation. <em>BMC Genomics 21, 6 (2020).</em> </p></li>
<li><p>Youden, W.J. (1950). Index for rating diagnostic tests.
<em>Cancer 3: 32-35.</em> </p></li>
<li><p>Powers, D.M.W. (2011). Evaluation: From Precision, Recall and
F-Measure to ROC, Informedness, Markedness &amp; Correlation.
<em>Journal of Machine Learning Technologies 2(1): 37–63.</em> </p></li>
<li><p>Chicco, D., Tötsch, N., Jurman, G. (2021). The Matthews
correlation coefficient (MCC) is more reliable than balanced accuracy,
bookmaker informedness, and markedness in two-class confusion matrix
evaluation. <em>BioData Min 14(1): 13.</em> </p></li>
<li><p>GlasaJeroen, A.S., Lijmer, G., Prins, M.H., Bonsel, G.J.,
Bossuyta, P.M.M. (2009). The diagnostic odds ratio: a single indicator
of test performance. <em>Journal of Clinical Epidemiology 56(11):
1129-1135.</em> </p></li>
<li><p>Wang H., Zheng H. (2013). Negative Predictive Value. <em>In:
Dubitzky W., Wolkenhauer O., Cho KH., Yokota H. (eds) Encyclopedia of
Systems Biology. Springer, New York, NY.</em> </p></li>
<li><p>Freeman, E.A., Moisen, G.G. (2008). A comparison of the
performance of threshold criteria for binary classification in terms of
predicted prevalence and kappa. <em>Ecol. Modell. 217(1-2): 45-58.</em>
</p></li>
<li><p>Balayla, J. (2020). Prevalence threshold (φe) and the geometry of
screening curves. <em>Plos one, 15(10):e0240215.</em> </p></li>
<li><p>Schaefer, J.T. (1990). The critical success index as an indicator
of warning skill. Weather and Forecasting 5(4): 570-575. </p></li>
<li><p>Hanley, J.A., McNeil, J.A. (2017). The meaning and use of the
area under a receiver operating characteristic (ROC) curve.
<em>Radiology 143(1): 29-36</em> </p></li>
<li><p>Hand, D.J., Till, R.J. (2001). A simple generalisation of the
area under the ROC curve for multiple class classification problems.
<em>Machine Learning 45: 171-186</em> </p></li>
<li><p>Mandrekar, J.N. (2010). Receiver operating characteristic curve
in diagnostic test assessment. <em>J. Thoracic Oncology 5(9):
1315-1316</em> </p></li>
</ol>
</div>
  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p></p>
<p>Developed by Adrian A. Correndo, Adrian A. Correndo, Luiz H. Moro Rosso, Rai Schwalbert, Carlos Hernandez, Leonardo M. Bastos, Luciana Nieto, Dean Holzworth, Ignacio A. Ciampitti.</p>
</div>

<div class="pkgdown-footer-right">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.7.</p>
</div>

    </footer>
</div>

  

  

  </body>
</html>
